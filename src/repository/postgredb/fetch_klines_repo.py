import time
import math
import logging
from repository.postgredb.db_connection import DatabaseConnection

logger = logging.getLogger(__name__)

class FetchKlinesRepository:
    def __init__(self, conn=None, cursor=None):
        if conn and cursor:
            self.conn = conn
            self.cursor = cursor
            self._own_connection = False
        else:
            db = DatabaseConnection()
            self.conn = db.connection
            self.cursor = self.conn.cursor()
            self._own_connection = True

    def save_batches(self, data, base_symbol, quote_symbol, batch_size=None):
        """
        Chia nh·ªè `data` th√†nh c√°c batch v√† insert v√†o DB.
        - `data`: list c√°c kline (m·ªói ph·∫ßn t·ª≠ l√† tuple/row)
        - `base_symbol`, `quote_symbol`: d√πng ƒë·ªÉ insert k√®m
        - `batch_size`: s·ªë d√≤ng m·ªói l·∫ßn executemany (m·∫∑c ƒë·ªãnh 10% t·ªïng)
        """
        try:
            formatted = [
                (
                    base_symbol,
                    quote_symbol,
                    row[0],  # trade_date
                    row[1],  # open_price
                    row[2],  # high_price
                    row[3],  # low_price
                    row[4],  # close_price
                    row[5],  # volume
                    row[8]   # trade_count
                )
                for row in data
            ]
            # ON CONFLICT ƒë·ªÉ tr√°nh duplicate
            sql = """
            INSERT INTO fact_coin_metrics (
                base_symbol, quote_symbol, trade_date, open_price,
                high_price, low_price, close_price, volume, trade_count
            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
            ON CONFLICT (base_symbol, trade_date) DO NOTHING;
            """

            total = len(formatted)
            if total == 0:
                logger.warning(f"‚ö†Ô∏è {base_symbol}: Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ insert.")
                return

            batch_size = batch_size or max(1, math.ceil(total * 0.1))
            bar_len = 20
            start_all = time.time()

            for i in range(0, total, batch_size):
                start = time.time()
                chunk = formatted[i : i + batch_size]
                self.cursor.executemany(sql, chunk)
                self.conn.commit()
                # Ghi log thanh ti·∫øn tr√¨nh + th·ªùi gian batch
                elapsed = time.time() - start
                done = i + len(chunk)
                pct = done / total * 100
                filled = int(bar_len * done // total)
                bar = '‚ñà' * filled + '-' * (bar_len - filled)

                logger.info(f"{base_symbol} ‚úÖ [{bar}] {pct:.2f}% - {done}/{total} d√≤ng - ‚è± {elapsed:.2f}s")
            # Ghi log t·ªïng th·ªùi gian
            logger.info(f"üèÅ {base_symbol} - Ho√†n t·∫•t insert, t·ªïng th·ªùi gian {time.time()-start_all:.2f}s")

        except Exception as e:
            self.conn.rollback()
            logger.error(f"‚ùå {base_symbol} - L·ªói khi insert d·ªØ li·ªáu: {e}")
            raise

    def close(self):
        """
        ƒê√≥ng connection/cursor n·∫øu ch√≠nh repository t·ª± t·∫°o.
        Service truy·ªÅn conn/cursor v√†o s·∫Ω t·ª± handle ƒë√≥ng.
        """
        if self._own_connection:
            self.cursor.close()
            self.conn.close()
            logger.info("üîí ƒê√£ ƒë√≥ng k·∫øt n·ªëi v·ªõi DB")