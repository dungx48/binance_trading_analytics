import time
import json
import logging

from repository.redis.redis_connection import RedisConnection
from constant.app_constant import AppConst
from repository.postgredb.db_connection import DatabaseConnection
from repository.postgredb.fetch_klines_repo import FetchKlinesRepository

# L·∫•y logger module
logger = logging.getLogger(__name__)

class ConsumeKlinesDailyService:
    """
    Consumer ch·∫°y li√™n t·ª•c ƒë·ªçc message t·ª´ Redis queue,
    ƒë·ªám v√†o buffer sau ƒë√≥ flush xu·ªëng DB theo batch ho·∫∑c theo th·ªùi gian.
    """
    MAX_BATCH = 500
    FLUSH_INTERVAL = 60  # gi√¢y
    QUEUE_KEY = AppConst.REDIS_KLINES_QUEUE

    def __init__(self):
        self.redis = RedisConnection().connection()

    def consume_and_push_to_db(self):
        """
        V√≤ng l·∫∑p ch√≠nh:
        - BLPOP v·ªõi timeout 5s ƒë·ªÉ kh√¥ng block v√¥ h·∫°n
        - ƒê·ªçc payload JSON, gom v√†o buffer
        - Khi buffer ƒë·ªß k√≠ch th∆∞·ªõc ho·∫∑c qu√° FLUSH_INTERVAL, g·ªçi _flush_to_db
        - Ti·∫øp t·ª•c loop v√¥ h·∫°n
        """
        logger.info("üöÄ Consumer ƒëang ch·∫°y li√™n t·ª•c...")
        buffer = []
        last_flush = time.time() # th·ªùi ƒëi·ªÉm flush cu·ªëi c√πng

        while True:
            try:
                # BLPOP: n·∫øu c√≥ message trong QUEUE_KEY th√¨ tr·∫£ v·ªÅ ngay,
                # n·∫øu kh√¥ng sau 5s s·∫Ω timeout (None) ƒë·ªÉ loop ti·∫øp
                item = self.redis.blpop(self.QUEUE_KEY, timeout=5)
                if item:
                    _, raw = item
                    try:
                        payload = json.loads(raw)
                        buffer.append(payload)
                    except json.JSONDecodeError as je:
                        logger.error(f"‚ùå JSON Decode Error: {je}")

                now = time.time()
                #    ƒêi·ªÅu ki·ªán flush:
                #    - ƒê·ªß MAX_BATCH messages
                #    - Ho·∫∑c ƒë√£ qu√° FLUSH_INTERVAL gi√¢y t·ª´ l·∫ßn flush tr∆∞·ªõc
                if buffer and (len(buffer) >= self.MAX_BATCH or now - last_flush >= self.FLUSH_INTERVAL):
                    self._flush_to_db(buffer)
                    buffer.clear()
                    last_flush = now

            except Exception as e:
                logger.error(f"‚ùå L·ªói kh√¥ng x√°c ƒë·ªãnh: {e}")

    def _flush_to_db(self, buffer):
        """
        M·ªü connection 1 l·∫ßn, d√πng FetchKlinesRepository ƒë·ªÉ insert t·∫•t c·∫£ payload trong buffer.
        """
        pending = len(buffer)
        logger.info(f"üçΩ Flush {pending} messages v√†o DB...")

        db = DatabaseConnection()
        conn = db.connection
        cursor = conn.cursor()
        repo = FetchKlinesRepository(conn, cursor)

        try:
            # V·ªõi m·ªói payload, validate v√† g·ªçi save_batches
            for payload in buffer:
                base = payload.get("base_symbol")
                quote = payload.get("quote_symbol")
                data = payload.get("data", [])
                if not base or not isinstance(data, list):
                    logger.error(f"‚ùå Payload kh√¥ng h·ª£p l·ªá: {payload}")
                    continue
                logger.info(f"üì• ƒêang insert {len(data)} d√≤ng c·ªßa {base}...")
                repo.save_batches(data, base, quote)

            logger.info(f"üèÅ Flush ho√†n t·∫•t {pending} messages.")
        except Exception as e:
            conn.rollback()
            logger.error(f"‚ùå L·ªói khi flush batch: {e}")
        finally:
            repo.close()

if __name__ == "__main__":
    consumer = ConsumeKlinesDailyService()
    consumer.consume_and_push_to_db()